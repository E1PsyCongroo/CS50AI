- Probability 概率
	不确定性可以表示为事件的数量以及每一事件发生的可能性或概率。
	- Possible Worlds 可能的世界
		每一种可能的情况都可以被认为是一个世界，用小写希腊字母ω表示。例如，滚动骰子可以产生六个可能的世界：骰子产生1的世界，骰子产生2的世界，等等。为了表示某个世界的概率，我们写`P(ω)`。
	- Axioms in Probability 概率公理
		- 0 < P(ω) < 1：表示概率的每个值必须介于0和1之间。
			- 0表示一个不可能的事件，就像掷一个标准骰子并得到7。
			- 1表示肯定会发生的事件，比如滚动骰子，得到的值小于10。
			- 通常，值越高，事件发生的可能性越大。
		- 所有可能事件的概率加起来等于1。$\sum_{\omega\in\varOmega}P(\omega)=1$
	- Unconditional Probability 无条件概率
			无条件概率是在没有任何其他证据的情况下对某一命题的相信程度。
- Conditional Probability 条件概率
	- 条件概率是给定一些已经揭示的证据，对某个命题的相信程度。
	- 条件概率用以下符号表示：`P(a|b)`，意思是“如果我们知道事件b已经发生，事件a发生的概率”，或者更简洁地说，“a在给定b下的概率”。
	- 数学上，为了计算a给定b下的条件概率，我们使用以下公式：$P(a|b)=\frac{P(a\land b)}{P(b)}$
	- 换言之，给定a给定b下的概率等于a和b为真概率除以b的概率。对此的一种直观推理方式是“我们对a和b均为真的事件（分子）感兴趣，但只对我们知道b为真（分母）的世界感兴趣”。“除以b将可能的世界限制为b为真的世界。以下是上式的代数等价形式：$$P(a\land b)=P(b)P(a|b)$$$$P(a\land b)=P(a)P(b|a)$$
- Random Variables 随机变量
	随机变量是概率论中的一个变量，具有一个可能取值域。例如，为了表示掷骰子时的可能结果，我们可以定义一个随机变量Roll，它可以取值{0，1，2，3，4，5，6}。为了表示航班的状态，我们可以定义一个变量flight，该变量取值为｛on time、delayed、canceled｝。
	通常，我们对每个值发生的概率感兴趣。我们使用概率分布来表示这一点。例如：
	 - P(_Flight = on time_) = 0.6
	-   P(_Flight = delayed_) = 0.3
	-   P(_Flight = canceled_) = 0.1
	概率分布可以更简洁地表示为向量。例如，$P(Flight)=<0.6, 0.3, 0.1>$。为了便于解释，这些值有一个设置的顺序（在我们的例子中，ontime、delayed、canceled）。
	- Independence 独立性
		独立性是指一个事件的发生不会影响另一个事件发生的概率。
		独立性可以用数学来定义：事件a和b是独立的，当且仅当a和b的概率等于a乘以b的概率：$P(a\land b)=P(a)P(b)$。
- Bayes’ Rule 贝叶斯规则
	贝叶斯规则通常用于概率论中计算条件概率。换句话说，贝叶斯规则表示：$P(b|a)=\frac{P(b)P(a|b)}{P(a)}$
- Joint Probability 联合概率
	联合概率是多个事件全部发生的可能性。
- Probability Rules 概率规则
	- Negation: $P(¬a) = 1 - P(a)$. 
	- Inclusion-Exclusion: $P(a \lor b) = P(a) + P(b) - P(a\land b)$. 这可以用以下方式解释：a或b为真的世界等于a为真的所有世界，加上b为真。然而，在这种情况下，有些世界被计算两次（a和b都为真的世界）。为了消除这种重叠，我们将a和b都为真的世界减去一次（因为它们被计算了两次）。
	- Marginalization 边缘化: $P(a) = P(a, b) + P(a, ¬b)$. 这里的想法是$b$和$\lnot b$是不相交的概率。也就是说，$b$$和$$\lnot b$同时发生的概率为0。我们也知道$b$和$\lnot b$的总和是1。因此，当a发生时，b可以发生也可以不发生。当我们把$a$和$b$发生的概率加上$a$和$\lnot b$的概率时，我们得到的就是a的概率。
		- 随机变量的边际化可以用以下方式表示：$P(X=x_i)=\sum_{j}P(X=x_i,Y=y_j)$
	- Conditioning: $P(a) = P(a | b)P(b) + P(a | ¬b)P(¬b)$.这是一个类似于边缘化的想法。事件a发生的概率等于$a$给定$b$下的概率乘以$b$的概率，再加上$a$给定$\lnot b$的概率除以$\lnot b$的概率。
		- $P(X=x_i)=\sum_{j}P(X=x_i|Y=y_j)P(Y=y_j)$
- Bayesian Networks 贝叶斯网络
	- 贝叶斯网络是一种表示随机变量之间依赖关系的数据结构。贝叶斯网络具有以下特征：
		- 它们是有向图。
		- 图上的每个节点表示一个随机变量。
		- 从X到Y的箭头表示X是Y的父级。也就是说，Y的概率分布取决于X的值。
		- 每个节点X具有概率分布$P(X|Parents(X))$。
	- Inference 推理
		- Query X 查询变量: 我们要计算概率分布的变量。
		- Evidence variables E 证据变量: 一个或多个被观测到的随机变量。
		- Hidden variables Y 隐藏变量: 不是query并且也没有被观测到的随机变量。
		- The goal 推理目标: 计算$P(X | e)$. 
	- Inference by Enumeration 枚举推理
		枚举推理是在给定被观测到的证据e和一些隐藏变量Y的情况下找到变量X的概率分布的过程。
		$$P(X|e)=\alpha P(X,e)=\alpha \sum_{y_i \in y}P(X,e,y_i)$$
		在这个等式中，$X$代表查询变量，$e$代表被观测到的证据，$y$代表隐藏变量的所有值，$α$将结果归一化，这样我们得到的概率加起来就是1。为了用文字来解释这个方程，我们认为给定$e$的$X$的概率分布等于$X$和$e$的归一化概率分布。为了得到这个分布，我们将$X$、$e$和$y$的归一化概率相加，其中$y_i$每次取隐藏变量$y$的不同值。
		- 关于$\alpha$：$P(a|b)=\frac{P(a\land b)}{P(b)}=\alpha P(a\land b),\alpha = \frac{1}{P(b)}$
- Sampling 采样
	采样是一种近似推断技术。在采样中，每个变量根据其概率分布进行采样。
	- Likelihood Weighting 似然加权
		- 首先固定证据变量的值。
		- 使用贝叶斯网络中的条件概率对非证据变量进行采样。
		- 根据每个样本的可能性对其进行加权。
- Markov Models 马尔科夫模型
	到目前为止，我们已经研究了条件概率问题。在这种范式中，时间的维度没有以任何方式表示。然而，许多任务确实依赖于时间维度，例如预测。为了表示时间变量，我们将创建一个新变量$X$，并根据感兴趣的事件对其进行更改，这样$X_t$ 是当前事件，$X_{t+1}$ 是下一个事件，依此类推。为了能够预测未来的事件，我们将使用马尔可夫模型。
	- The Markov Assumption 马尔科夫假设
		马尔可夫假设是一种假设，即当前状态仅取决于有限固定数量的先前状态。这对我们很重要。想想预测天气的任务。理论上，我们可以利用过去一年的所有数据来预测明天的天气。然而，这是不可行的，既因为这需要庞大的计算能力，也因为基于365天前的天气，可能没有关于明天天气的条件概率的信息。使用马尔可夫假设，我们限制了之前的状态（例如，在预测明天的天气时，我们只考虑之前的几天），从而使任务变得可管理。这意味着我们可能会得到更粗略的感兴趣概率的近似值，但这通常足以满足我们的需要。此外，我们可以使用基于最后一个事件的信息的马尔可夫模型（例如，基于今天的天气预测明天的天气）。
	- Markov Chain 马尔科夫链
		马尔可夫链是一个随机变量序列，其中每个变量的分布遵循马尔可夫假设。也就是说，链中的每个事件都基于其之前事件的概率发生。
		为了构建马尔可夫链，我们需要一个**Transition Model**转移模型，该模型明确下一事件基于当前事件的概率分布。
	- Hidden Markov Models 隐马尔科夫模型
		隐马尔可夫模型是一种用于具有隐状态的系统的马尔可夫模型，该隐藏状态产生一些观察到的事件。这意味着，有时，人工智能可以对世界进行一些测量，但无法获取世界的精确状态。在这些情况下，世界的状态被称为**Hidden State**隐藏状态，人工智能所访问的任何数据都是**Observations**观察结果。
		基于隐马尔可夫模型，可以实现多个任务:
		- Filtering：给定从开始到现在的观测值，计算当前状态的概率分布。
		- Prediction：给定从开始到现在的观测，计算未来状态的概率分布。
		- Smoothing：给定从开始到现在的观测，计算过去状态的概率分布。
		- Most likely explanation：给定从开始到现在的观测，计算最可能的事件序列。