- Optimization
	优化是从一组可能的选项中选择最佳选项。
- Local Search 局部搜索
	局部搜索是一种保持单个节点并通过移动到相邻节点进行搜索的搜索算法。这种类型的算法与我们看到的以前类型的搜索不同。例如，在迷宫求解中，我们希望找到最快的方法来达到目标，而局部搜索则希望找到问题的最佳答案。通常，局部搜索会得到一个不是最优的但“足够好”的答案，从而节省计算能力。
	- 重要术语：
		- Objective Function 目标函数：目标函数是我们用来最大化解决方案价值的函数。
		- Cost Function 代价函数：代价函数是我们用来最小化解决方案成本的函数。
		- Current State 当前状态：当前状态是函数当前正在考虑的状态。
		- Neighbor State 领近状态：领近状态是当前状态可以转换到的状态。
	- Hill Climbing 爬山算法
		爬山算法是一种局部搜索算法。在该算法中，将邻近状态与当前状态进行比较，如果其中任何一个状态更好，我们将当前节点从当前状态更改为该邻居状态。更好的定义取决于我们是使用目标函数，偏好更高的值，还是使用递减函数，偏好更低的值。
		```
	    current = initial state of problem
	    repeat:
			neighbor = best valued neighbor of current
			if neighbor not better than current:
				return current
			current = neighbor
		```
	- Local and Global Minima and Maxima 局部最大（小）值和整体最大（小）值
		爬山算法可能陷入局部最大值或最小值。局部最大（小）值是具有比其领近状态更高（低）的值的状态。与此相反，全局最大（小）值是状态空间中所有状态中具有最高（低）值的状态。
	- Hill Climbing Variants 爬山算法变体
		由于爬山算法的局限性，人们考虑了多种变体来克服陷入局部极小值和极大值的问题。该算法的所有变体都有一个共同点，即无论采用何种策略，每一种算法都有可能以局部最小值和最大值结束，而无法继续优化。下面的算法是这样表述的，即值越高越好，但它们也适用于代价函数，其目标是最小化代价。
		- Steepest-ascent 最陡上升算法：选择价值最高的领近状态。
		- Stochastic 随机选择算法：从价值较高的领近状态中随机选择。
		- First-choice 第一选择算法：选择第一个价值较高的领近状态。
		- Random-restart 随机重启算法：多次爬山。每次都从随机状态开始。比较每次爬山的最大值，并从中选择最高值。
		- Local Beam Search 局部束搜索算法：选择k个最高值的邻居。这与大多数局部搜索算法不同，因为它使用多个节点进行搜索，而不仅仅是一个。
	- 尽管局部搜索算法并不总是能给出最佳解决方案，但在考虑到每个可能状态都是计算上不可行（时间复杂度过高）的情况下，它们通常可以给出足够好的解。
	- Simulated Annealing 模拟退火算法
		模拟退火算法在陷入局部最大值时“移动”自身。
		```
		current = initial state of problem
		for t = 1 to max:
			T = Temperature(t)
			neighbor = random neighbor of current
			ΔE = how much better neighbor is than current
			if ΔE > 0:
				current = neighbor
			with probability e^(ΔE/T) set current = neighbor
		return current
		```
- Linear Programming 线性规划
	线性规划是一系列优化线性方程的问题
	线性规划将包含以下组成：
	- Cost function 代价函数：$c₁x₁ + c₂x₂ + … + cₙxₙ$
	- Constraint 约束条件：表示为小于或等于某个值的变量的总和($a₁x₁ + a₂x₂ + … + aₙxₙ ≤ b$)或正好等于此值($a₁x₁ + a₂x₂ + … + aₙxₙ = b$)
	- Individual bounds 变量边界：$l_i ≤ x_i ≤ u_i$
- Constraint Satisfaction 约束满足
	约束满足问题是一类在满足某些条件的同时需要为变量赋值的问题。
	- 约束满足问题具有以下组成：
		- 一系列变量：$x₁, x₂, …, xₙ$
		- 每个变量的值域：$D₁, D₂, …, Dₙ$
		- 一系列约束：C
	- 术语：
		- Hard Constraint 硬约束：硬约束是在正确的解决方案中必须满足的约束。
		- Soft Constraint 软约束：软约束是表示哪个解决方案优于其他解决方案的约束。
		- Unary Constraint 一元约束：一元约束是仅涉及一个变量的约束。
		- Binary Constraint 二元约束：二进制约束是包含两个变量的约束。
	- Node Consistency 结点一致性
		结点一致性是指变量值域中的所有值都满足变量的一元约束。
	- Arc Consistency 弧一致性
		弧一致性是指变量值域中的所有值都满足变量的二元约束。
		```
		function Revise(csp, X, Y): # 使变量X，Y在约束csp中满足弧一致性
			revised = false
			for x in X.domain:
				if no y in Y.domain satisfies constraint for (X,Y):
					delete x from X.domain
					revised = true
			return revised
		```
		该算法首先使用revised变量跟踪X的域是否发生了任何变化。这将在我们研究的下一个算法中有用。然后，代码对X域中的每个值重复，并查看Y是否具有满足约束的值。如果是，则不执行任何操作，如果不是，则从X的域中删除该值。
		- 通常，我们感兴趣的是使整个问题保持一致，而不仅仅是一个变量与另一个变量之间的关系。在这种情况下，我们将使用名为`AC-3`的算法，该算法使用函数Revise：
		```
		function AC-3(csp):
			queue = all arcs in csp
			while queue non-empty:
				(X, Y) = Dequeue(queue)
				if Revise(csp, X, Y):
					if size of X.domain == 0:
						return false
					for each Z in X.neighbors - {Y}:
						Enqueue(queue, (Z,X))
			return true
		```
		该算法将问题中的所有弧添加到队列中。每次考虑弧时，都会将其从队列中删除。然后，它运行Revise算法以查看此弧是否一致。如果进行了更改以使其保持一致，则需要采取进一步的行动。如果X的结果域是空的，这意味着这个约束满足问题是不可解决的（因为没有X可以取的值允许Y取任何给定约束的值）。如果问题在前一步中被认为是不可解决的，那么，由于X的域被更改，我们需要查看与X相关的所有弧是否仍然一致。也就是说，我们获取除Y之外的所有X的领近，并将它们和X之间的弧添加到队列中。然而，如果Revise算法返回false，意味着域没有更改，我们只需继续考虑其他弧。
		- 虽然弧一致性算法可以简化问题，但它不一定能解决问题，因为它只考虑二元约束，而不考虑多个节点如何互连。
	- 约束满足问题可视为搜索问题：
		- Initial state：空赋值（所有变量都没有赋值）。
		- Actions：对变量赋值(variable=value)，也就是说，给某个变量一个值。
		- Transition model：显示添加赋值如何更改分配。
		- Goal test：检查是否为所有变量分配了一个值，是否满足所有约束条件。
		- Path cost function：所有路径的成本相同。正如我们前面提到的，与典型的搜索问题不同，优化问题关心的是解决方案，而不是解决方案的路径。
	- Backtracking Search 回溯搜索算法
		回溯搜索是一种考虑到约束满足搜索问题结构的搜索算法。通常，它是一个递归函数，只要满足约束条件，它就尝试继续赋值。如果违反了约束，它将尝试不同的赋值。
		```
		function Backtrack(assignment, csp):
			if assignment complete:
				return assignment
			var = Select-Unassigned-Var(assignment, csp)
			for value in Domain-Values(var, assignment, csp):
				if value consistent with assignment:
					add {var = value} to assignment
					result = Backtrack(assignment, csp)
					if result ≠ failure:
						return result
					remove {var = value} from assignment
			return failure
		```
		换句话说，如果当前赋值完成，该算法首先返回当前赋值分配。如果赋值未完成，算法将选择尚未赋值的任何变量。然后，算法尝试为变量赋值，并对结果赋值（递归）再次运行Backtrack算法。然后，它检查结果值。如果不是失败，则意味着任务完成了，它应该返回此赋值分配。如果结果值失败，则删除最新的赋值，并尝试新的可能值，重复相同的过程。如果域中所有可能的值都返回失败，这意味着我们需要回溯。也就是说，问题出在之前的一些赋值分配上。如果这发生在我们开始的变量上，那么这意味着没有解决方案满足约束条件。
	- Inference 推理
		尽管回溯搜索比简单搜索更有效，但它仍然需要大量的算力。另一方面，执行弧一致性算法的资源消耗较少。通过将回溯搜索与推理交织（弧一致性算法），我们可以得到一个更有效的算法。该算法称为**保持弧一致性**算法。该算法将在每一次新的回溯搜索赋值后执行弧一致性算法。具体地说，在我们对X进行新的赋值之后，我们将调用`AC-3`算法，并从所有弧（Y，X）的队列开始，其中Y是X的领近（而不是问题中所有弧的队列）。以下是一个修改后的回溯算法，该算法保持了弧的一致性。
		```
		function Backtrack(assignment, csp):
			if assignment complete:
				return assignment
			var = Select-Unassigned-Var(assignment, csp)
			for value in Domain-Values(var, assignment, csp):
				if value consistent with assignment:
					add {var = value} to assignment # changed
					inferences = Inference(assignment, csp) # changed
				if inferences ≠ failure:
					add inferences to assignment
				result = Backtrack(assignment, csp)
				if result ≠ failure:
					return result
				remove {var = value} and inferences from assignment # changed
			return failure
		```
		推理函数运行`AC-3`算法，如所述。它的输出是通过弧一致性可以得出的所有推论赋值分配。从字面上看，这些是可以从以前的赋值分配和约束满足问题的结构中推断出的新赋值分配。
	- 还有其他方法可以使算法更有效。到目前为止，我们随机选择了一个未赋值的变量。然而，有些选择比其他选择更可能更快地找到解决方案。这需要使用**heuristic**启发式算法。启发式是一种经验法则，这意味着，通常情况下，它会比遵循天真的方法带来更好的结果，但这并不一定能做到。
		- Minimum Remaining Values (MRV) heuristic 最小剩余值：这里的想法是，如果一个变量的域被推理限制，而现在它只剩下一个值（或者即使它是两个值），那么通过进行这个赋值，我们将减少以后可能需要做的回溯次数。也就是说，我们迟早要进行这个赋值，因为它是从弧一致性推断出来的。如果这项任务失败了，最好尽快发现它，而不是事后再回头。
		- Degree heuristic 度启发式：度启发式依赖于变量的度，其中度是将变量连接到其他变量的弧数。通过选择具有最高程度的变量，通过一次赋值，我们约束了多个其他变量，从而加快了算法的过程。
	- 另一种使算法更有效的方法是，当我们从变量域中选择值时，采用另一种启发式方法。
		- Least Constraining Values heuristic 最小约束值：通过最小约束值算法我们选择将约束最少其他变量的值。这里的想法是，虽然在度启发式中，我们希望使用更可能约束其他变量的变量，但在这里我们希望该变量对其他变量的约束最小。也就是说，我们希望找到可能是最大潜在麻烦源的变量（度最高的变量），然后使其尽可能不麻烦（为其分配最小的约束值）。