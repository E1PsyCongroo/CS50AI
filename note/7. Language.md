- Language
	- **Natural Language Processing**（NLP——自然语言处理）涵盖人工智能将人类语言作为输入的所有任务。以下是此类任务的几个示例：
		- automatic summarization 自动摘要，其中 AI 以文本作为输入，并生成文本摘要作为输出。
		- information extraction 信息提取，其中给 AI 一个文本语料库，AI 提取数据作为输出。
		- language identification 语言识别，AI 被赋予文本并返回文本的语言作为输出。
		- machine translation 机器翻译，AI 收到原始语言的文本，并输出目标语言的翻译。
		- named entity recognition 命名实体识别，其中给 AI 文本并提取文本中实体的名称（例如，公司名称）。
		- speech recognition 语音识别，AI 被赋予语音并在文本中生成相同的单词。
		- text classification 文本分类，给 AI 文本，它需要将其分类为某种类型的文本。
		- word sense disambiguation 词义消歧，AI 需要从具有多重含义的单词中选择正确的含义（例如，bank 既表示金融机构，也表示河边的地面）。
	- Syntax and Semantics 语法和语义
		- **Syntax**语法是指句子结构。作为一些人类语言的母语使用者，我们并不纠结于产生符合语法的句子，而将不符合语法的句子标记为错误。语法可以同时具有语法性和模糊性。
		- **Semantics**语义是指词语或句子的含义。
	- Context-Free Grammar 上下文无关文法
		- **Formal Grammar**（形式语法）是一个用于生成语言中的句子的规则系统。在上下文无关文法中，文本被从其含义中抽象出来，用形式语法来表示句子的结构。让我们考虑一下下面的例句。
		![[source/7-1.png]]
		使用形式化的语法，人工智能能够代表句子的结构。在我们描述的语法中，有足够的规则来表示上面的简单句子。为了表示更复杂的句子，我们将不得不在形式化语法中添加更多的规则。
		- n-grams
			n-gram是一个文本样本的n个项目的序列。
			n-grams对文本处理很有用。虽然人工智能以前不一定见过整个句子，由于有些词在一起出现的频率比其他的高，所以也有可能以一定的概率预测下一个词。
		- Tokenization 标记化
			标记化是将一连串的字符分割成碎片（tokens）的任务。标记可以是词，也可以是句子，在这种情况下，这项任务被称为**word tokenization**（词标记化）或**sentence tokenization**（句子标记化）。
		- Markov Models 马尔科夫模型
		- Bag-of-Words Model 词袋模型
			词袋是一种将文本表示为无序的词语集合的模型。这种模型忽略了语法，只考虑句子中的词的含义。
		- Naive Bayes 朴素贝叶斯
		- Information Retrieval 信息检索
			信息检索是为响应用户查询而寻找相关文件的任务。为了实现这一任务，我们使用主题建模来发现一组文件的主题。人工智能如何去提取文档的主题呢？一种方法是通过查看术语频率，即简单地计算一个术语在文档中出现的次数。
		- Information Extraction 信息提取
			信息提取是指从文档中提取知识的任务。
		- Word Representation 词汇表征
			- One-Hot Representation
			- Distributed Representation 分布式表征
		- word2vec 
			word2vec是一种生成单词的分布式表示的算法。它是通过Skip-Gram架构来实现的，这是一种预测目标词上下文的神经网络架构。在这个架构中，神经网络对每个目标词都有一个输入单元。一个较小的、单一的隐藏层（例如50或100个单元，尽管这个数字是灵活的）将产生代表词的分布式表示的值。这个隐藏层的每个单元都与输入层的每个单元相连。输出层将生成可能出现在与目标词相似的语境中的词。
			![[source/7-2.png]]